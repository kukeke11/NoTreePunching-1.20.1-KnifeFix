name: Test Client Run

on:
  workflow_dispatch:
    inputs:
      timeout:
        description: 'Client timeout in seconds'
        required: false
        default: '600'
        type: string
      memory:
        description: 'Client memory allocation (e.g., 4G)'
        required: false
        default: '4G'
        type: string
      log_level:
        description: 'Log level (debug, info, warn, error)'
        required: false
        default: 'info'
        type: choice
        options:
          - debug
          - info
          - warn
          - error
  push:
    paths:
      - 'Common/src/**'
      - 'Forge/src/**'
      - 'scripts/**'
      - '.github/workflows/test-client-run.yml'
  pull_request:
    paths:
      - 'Common/src/**'
      - 'Forge/src/**'
      - 'scripts/**'

env:
  JAVA_VERSION: '17'
  GRADLE_OPTS: '-Dorg.gradle.daemon=false -Dorg.gradle.workers.max=2'

jobs:
  test-client:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    
    strategy:
      fail-fast: false
      matrix:
        include:
          - name: "Standard Test"
            timeout: ${{ inputs.timeout || '300' }}
            memory: ${{ inputs.memory || '3G' }}
            log_level: ${{ inputs.log_level || 'info' }}
          - name: "Debug Test"
            timeout: "180"
            memory: "4G" 
            log_level: "debug"
    
    name: ${{ matrix.name }}
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Set up JDK ${{ env.JAVA_VERSION }}
        uses: actions/setup-java@v4
        with:
          distribution: 'temurin'
          java-version: ${{ env.JAVA_VERSION }}
          cache: 'gradle'
          
      - name: Setup Virtual Display (Xvfb)
        run: |
          sudo apt-get update -qq
          sudo apt-get install -y xvfb mesa-utils libgl1-mesa-dri
          export DISPLAY=:99
          Xvfb :99 -screen 0 1024x768x24 -ac +extension GLX +render -noreset &
          echo "DISPLAY=:99" >> $GITHUB_ENV
          # Wait for display to be ready
          sleep 3
          # Verify display is working
          DISPLAY=:99 glxinfo | head -5 || echo "GLX not available, continuing anyway"
          
      - name: Validate Gradle Wrapper
        run: |
          cd ${{ github.workspace }}
          ./gradlew --version
          
      - name: Build Project
        run: |
          ./gradlew :Forge:classes --no-daemon --console=plain
          
      - name: Run Client Test
        id: client_test
        run: |
          # Set up environment
          export CLIENT_TIMEOUT="${{ matrix.timeout }}"
          export CLIENT_MEMORY="${{ matrix.memory }}"
          export FORGE_LOG_LEVEL="${{ matrix.log_level }}"
          export HEADLESS_MODE="true"
          export CI_MODE="true"
          
          # Create results directory
          mkdir -p test-results
          
          echo "Starting client test with configuration:"
          echo "  Timeout: ${CLIENT_TIMEOUT}s"
          echo "  Memory: ${CLIENT_MEMORY}"
          echo "  Log Level: ${FORGE_LOG_LEVEL}"
          
          # Run the client test
          set +e
          timeout ${{ matrix.timeout }} ./scripts/run-client-with-logging.sh \
            --headless \
            --ci-mode \
            --timeout ${{ matrix.timeout }} \
            --memory ${{ matrix.memory }} \
            --log-level ${{ matrix.log_level }}
          
          client_exit_code=$?
          echo "client_exit_code=$client_exit_code" >> $GITHUB_OUTPUT
          
          # Handle timeout (exit code 124 from timeout command)
          if [ $client_exit_code -eq 124 ]; then
            echo "❌ Client test timed out after ${{ matrix.timeout }} seconds"
            echo "test_result=timeout" >> $GITHUB_OUTPUT
          elif [ $client_exit_code -eq 0 ]; then
            echo "✅ Client test completed successfully"
            echo "test_result=success" >> $GITHUB_OUTPUT
          else
            echo "❌ Client test failed with exit code: $client_exit_code"
            echo "test_result=failed" >> $GITHUB_OUTPUT
          fi
          
          # Always continue to collect logs and artifacts
          set -e
          
      - name: Analyze Logs
        if: always()
        run: |
          echo "Analyzing client logs..."
          
          # Find the most recent log files
          if [ -d "Forge/run/logs" ]; then
            echo "Available log files:"
            ls -la Forge/run/logs/ || true
            
            # Analyze the latest log if available
            if [ -f "Forge/run/logs/latest.log" ]; then
              echo "Analyzing latest.log..."
              ./scripts/analyze-client-logs.sh --format json Forge/run/logs/latest.log > test-results/log-analysis.json || echo "Log analysis failed"
              
              # Generate text summary for GitHub output
              ./scripts/analyze-client-logs.sh --format summary Forge/run/logs/latest.log > test-results/log-summary.txt || echo "Log summary failed"
              
              echo "Log Analysis Summary:"
              cat test-results/log-summary.txt || echo "No summary available"
            else
              echo "⚠️ No latest.log found for analysis"
            fi
            
            # Check for specific mod loading
            if grep -q "ModContainer.*notreepunching.*successfully loaded" Forge/run/logs/latest.log 2>/dev/null; then
              echo "✅ No Tree Punching mod loaded successfully"
              echo "mod_loaded=true" >> $GITHUB_OUTPUT
            else
              echo "❌ No Tree Punching mod did not load"
              echo "mod_loaded=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "⚠️ No log directory found"
          fi
          
      - name: Collect System Information
        if: always()
        run: |
          echo "Collecting system information for debugging..."
          
          cat > test-results/system-info.txt << EOF
          === System Information ===
          Date: $(date -u)
          OS: $(uname -a)
          Java Version: $(java -version 2>&1)
          Memory: $(free -h)
          CPU: $(nproc) cores
          Disk Space: $(df -h .)
          Display: $DISPLAY
          
          === Environment Variables ===
          $(env | grep -E "(JAVA|GRADLE|CLIENT|FORGE|DISPLAY)" | sort)
          
          === Process Information ===
          $(ps aux | head -10)
          EOF
          
      - name: Upload Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: client-test-results-${{ matrix.name }}-${{ github.run_number }}
          path: |
            test-results/
            Forge/run/logs/
            Forge/run/crash-reports/
          retention-days: 7
          if-no-files-found: warn
          
      - name: Upload Build Logs
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: build-logs-${{ matrix.name }}-${{ github.run_number }}
          path: |
            build/
            Forge/build/
            .gradle/
          retention-days: 3
          if-no-files-found: warn
          
      - name: Comment on PR
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const testResult = '${{ steps.client_test.outputs.test_result }}';
            const modLoaded = '${{ steps.client_test.outputs.mod_loaded }}';
            const clientExitCode = '${{ steps.client_test.outputs.client_exit_code }}';
            const matrixName = '${{ matrix.name }}';
            
            let emoji = '❓';
            let status = 'Unknown';
            
            if (testResult === 'success') {
              emoji = '✅';
              status = 'Success';
            } else if (testResult === 'timeout') {
              emoji = '⏱️';
              status = 'Timeout';
            } else if (testResult === 'failed') {
              emoji = '❌';
              status = 'Failed';
            }
            
            const comment = `
            ## ${emoji} Client Test Results - ${matrixName}
            
            **Status:** ${status}
            **Exit Code:** ${clientExitCode}
            **Mod Loaded:** ${modLoaded === 'true' ? '✅ Yes' : '❌ No'}
            **Configuration:**
            - Timeout: ${{ matrix.timeout }}s
            - Memory: ${{ matrix.memory }}
            - Log Level: ${{ matrix.log_level }}
            
            **Artifacts:**
            - Test results and logs are available in the workflow artifacts
            - Log analysis and system information collected
            
            ${testResult === 'success' ? '🎉 The client ran successfully and the mod loaded properly!' : 
              testResult === 'timeout' ? '⚠️ The client test exceeded the timeout limit. Consider increasing timeout or checking for startup issues.' :
              '💥 The client test failed. Check the logs for detailed error information.'}
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
            
      - name: Set Job Summary
        if: always()
        run: |
          echo "## 🎮 Client Test Summary - ${{ matrix.name }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Result:** ${{ steps.client_test.outputs.test_result }}" >> $GITHUB_STEP_SUMMARY
          echo "**Exit Code:** ${{ steps.client_test.outputs.client_exit_code }}" >> $GITHUB_STEP_SUMMARY
          echo "**Mod Loaded:** ${{ steps.client_test.outputs.mod_loaded }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Configuration:**" >> $GITHUB_STEP_SUMMARY
          echo "- Timeout: ${{ matrix.timeout }}s" >> $GITHUB_STEP_SUMMARY
          echo "- Memory: ${{ matrix.memory }}" >> $GITHUB_STEP_SUMMARY
          echo "- Log Level: ${{ matrix.log_level }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "test-results/log-summary.txt" ]; then
            echo "**Log Analysis:**" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            cat test-results/log-summary.txt >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi
          
  # Summary job that depends on all test jobs
  test-summary:
    if: always()
    needs: test-client
    runs-on: ubuntu-latest
    steps:
      - name: Check Test Results
        run: |
          echo "All client tests completed"
          
          # Check if any tests failed
          if echo '${{ toJson(needs.test-client.outputs) }}' | jq -r '.[]' | grep -q 'failed\|timeout'; then
            echo "❌ Some client tests failed or timed out"
            exit 1
          else
            echo "✅ All client tests passed"
          fi